## MySQL

### 关系型数据库

> 数据库就是一个文件系统,通过标准SQL语句(结构查询语句)才能访问

关系型和非关系主要指的是数据库中数据的存储格式，关系型存储格式按照一定的模型，比如一对一，一对多等，一般是二维表的形式，比较容易理解，但占用空间大，一般会有持久化方案，比较安全；非关系型有键值对，文档类型，比如redis，它们的特点是占用空间小，但是不容易理解，一般存在内存中，访问速度比较快。

(1)windows命令窗口

```
[net start mysql]				启动服务
[mysql -uroot -padmin]			登录
mysqladmin -uname -poldpwd password newpwd			修改密码
	参考:https://blog.csdn.net/th_num/article/details/71402801
```

(2)数据库的备份与还原

```
备份数据库:[mysqldump -uroot -p199465 store > d:/store.sql]	
还原数据库:
	1.创建同名数据库:[create database store;]
	2.选择使用该数据库:[use store;]
	3.还原:[source c:/store.sql;]
```

### MySQL的数据类型

- 整型: TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT,分别使用 8, 16, 24, 32, 64 位存储空间
  INT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的
- 浮点型: FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型.
  浮点型都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数
- 字符串: 主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。
- 日期: DATETIME 和 TIMESTAMP
  TIMESTAMP和时区有关，也就是说一个时间戳在不同的时区所代表的具体时间是不同的
  应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。

### SQL语句

> SQL语句:DDL DML DCL DQL
>

**DDL:数据定义语言**

```
// 数据库
create database 数据库名;
show databases;
show create database 数据库名;
drop database 数据库名;
use 数据库名;
select database(); // 查看正在使用的数据库
```

```
// 表
show create table [表名];
create table 表名(字段描述,字段描述...);
show tables;
desc 表名;
drop table 表名;

alter table 表名 raname to 新表名;
alter table 表名 add 字段描述;
alter table 表名 change 旧列名 新列名 旧描述;
alter table 表名 modify 旧列表 新表述;
alter table 表名 drop 列名;

truncate 表名;
```

```
// 建表语句示例
create table product(
	id int(11) not null auto_increment,
    name varchar(255) default null,
    price float default null,
    cid int(11) default null,
    createDate datetime default null,
    primary key (id),
    constraint fk_product_category foreign key (cid) references category (id)
) engine=innodb default charset=utf8;
```

**DML:数据修改语言**

```
insert into 表名(字段1,字段2...) values(1值,2值...) [条件];

update 表名 set 字段1=值1,字段2=值2... [条件];

delete from 表名 [条件];
```

**DQL:数据查询语言**

> select * from 表名 where... group by ... having ... order by ... [asc|desc]

```
select [distinct]*[列名,列名] from 表名 [条件];
```

```
// where 条件
in(min,max)
between...and...
...like "__"|"开头%"|"结尾%"|"%中间%"
```

```
// 聚合函数
sum() avg() max() min() count()
```

```
----查询语句实例----
select * from product where id = ? limit start_,count_;
--其中start_决定了结果从第几条开始算,count决定了结果一共有几条
```

**多表关系**

```
// 一对一
可以创建成一张表,或者建立外键
```

```
// 一对多
多表的一方创建一个字段,作为指向另一方的主键
```

```
// 多对多
创建第三张中间表,中间表包含两个字段,分别作为双方的主键外键
```

**多表查询**

```
// 内连接查询:不满足条件的双方都不展示
select * from tableA join tableB on 条件
```

```
// 外连接查询:全部展示左(右)方
select * from tableA left join tableB on 条件
```

```
// 子查询
查询的结果作为一个数|一个区间|一张表(可以取别名)放入另一个查询语句
```

### delte,truncate,drop

```
// delete
1.DML语句,执行的操作可以rollback
2.可以删除一行,也可以删除全部记录,但是不会删除表占用的空间(比如自增的id不会重置)

// truncate
1.DDL语句,执行的操作不可以rollback(但是也可以恢复)
2.清空表的全部记录,将表占用空间重置为默认初始值(id会重置)

// drop
1.DDL语句,不能rollback(但是也可以恢复)
2.清空表的全部记录,并释放表占用的所有空间

总的来说:
1.执行速度:drop>tuncate>delete
2.虽然都能恢复,但是delete恢复最方便
3.对于外键约束引用的表,要清空表不能用trunate,只能用不带where的delete
4.整理表的碎片,可以用truncate + reuse storage,然后重新导入数据
```



## 日志

MySQL 里有两个日志，即：重做日志（redo log）和归档日志（binlog）。

binlog 以二进制形式记录了所有的 `DDL` 和 `DML` 语句（除了数据查询语句select、show等）, 每一个数据库更新操作都对应一个事件存储, 主要使用场景是主从复制，它是实现在 server 层的，所有引擎可以共用。

redo log 是 InnoDB 特有的日志，用来支持 crash-safe 能力，是事务持久性的实现基础。

### MySQL事务的两段提交

在事务提交的时候，分成 prepare 和 commit 两个阶段：redo log 先 prepare 完成，再写 binlog，最后才进入 redo log commit 阶段。

如下图是一个update语句的执行流程（MySQL中未显式开启事务，每个sql都认为是一个事务，且自动commit）

![1565585881192](d:/resource/notePic/1565585881192.png)

事务的两段提交是为了保证，在发生崩溃恢复时，redolog和binlog保持一致性，即主从保持一致性。崩溃恢复时的判断规则如下：

1. 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；
2. 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：
a. 如果是，则提交事务；
b. 否则，回滚事务。



### 对两段提交存在的问题

#### 为什么要两段提交？

可以假设如果没有两段提交，反证存在的问题。

先提交redolog，再写binlog（这一步崩溃）：对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（redolog 处于 prepare 状态的时候，其它事务日志是进不来的，等其变成 commit 状态后，才会继续下一个事务写 redolog，所以这里回滚就可能覆盖掉别的事务的更新）。这样binlog就会和redolog不一致

先写binlog，再提交redolog（这一步崩溃）：binlog 写入成功就会被从库（或者用这个 binlog 恢复出来的库）使用（可以认为binlog是没有回退的），而此时redolog并没有成功写入，崩溃恢复时，“主”找不到这条改变记录，但是“从”却已从binlog同步过去了

#### 如果最后一步提交事务commit状态发生崩溃，怎么回滚？

按照崩溃恢复的判断规则，这种崩溃恢复时检查发现，redolog有完整的 prepare，binlog是完整的。因此会提交事务，而不是回滚。那这是否违背了事务的要求（失败则回滚）呢？

其实没有违背，因为最后一步commit并不是事务处理内容的一部分，它只是用于记录事务提交状态，它崩溃对事务要处理的内容本身没有影响，并且事务的crash一般也就出在这个阶段, 所以认为这种情况是不用回滚的。

#### MySQL 怎么知道 binlog 是完整的?

一个事务的 binlog 是有完整格式的。statement 格式的 binlog，最后会有 COMMIT；row 格式的 binlog，最后会有一个 XID event。

#### redo log 和 binlog 是怎么关联起来的?

它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：

- 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
- 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

#### 不要redolog，使用binlog承担其功能可以吗？

MySQL 的原生引擎是 MyISAM，设计之初binlog就没有支持崩溃恢复（不能记录数据页的更改）。因此必须使用InnoDB的redo log。（必须两个 log 对比，才能知道是否该恢复）

#### 那只用 redo log，不要 binlog可以吗？

如果只从崩溃恢复的角度来讲是可以的。但是 binlog 有着 redo log 无法替代的功能。

一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。

一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方，比如主从复制就需要它。



## 事务

MySQL事务默认隔离级别是repeatable read, 且自动开启事务. 自动开启事务状态下, 如果没有显式声明开启事务, 那么每一条sql都会被认为是一个事务且自动提交.

Oracle默认隔离级别是read committed, 需要手动开启事务.

### MySQL服务器的逻辑架构

![1565337586139](d:/resource/notePic/1565337586139.png)

如上图所示，MySQL服务器逻辑架构从上往下可以分为三层：

（1）第一层：连接层，处理客户端连接、授权认证等。

（2）第二层：服务器层，负责查询语句的解析、优化、缓存以及内置函数的实现、存储过程等。

（3）第三层：存储引擎，负责MySQL中数据的存储和提取。**MySQL中服务器层不管理事务，事务是由存储引擎实现的。**MySQL支持事务的存储引擎有InnoDB、NDB Cluster等，其中InnoDB的使用最为广泛；其他存储引擎不支持事务

### 事务的特性:ACID

- **原子性**: 事务是一个基本操作单元, 事务中的操作要么全部成功, 要么全部失败
- **持久性**: 事务执行完成后, 数据的修改就会持久到数据库中(即使发生断电故障)
- **隔离性**: 事务在提交前的操作是对其他事务不可见的
- **一致性**: 数据库在事务执行前后都保持一致性的状态

![1553133929206](/d:/resource/notePic/1553133929206.png)

### 原子性和持久性的实现原理

- 原子性的实现原理: 原子性保证事务在回滚时能够正常回滚, 是通过**undo日志**实现的, 在事务进行时, 每一次对数据库的更改都会在undo日志中对应生成一条记录, 保证执行该记录可以回退到修改前的状态.
- 持久性的实现原理: 通过redo日志实现, 数据库为了提供效率, 并不是每条修改都直接同步到磁盘中, 但是每条提交的修改都会记录在**redo日志**中, 并使用后台线程定期同步到磁盘中, 如果发生断电类的事故, 机器再次启动后会执行redo中的记录, 保证数据不丢失.
- 一致性的实现原理: 一致性即保证数据库在事务提交前后保持一致的状态, 这个是建立在原子性 / 持久性 / 隔离性的基础上

**既然redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快呢？**

（1）刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO。

（2）刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入；而redo log中只包含真正需要写入的部分，无效IO大大减少。

### 隔离性

#### 读写并发存在的问题

- **脏读**: 事务A修改了数据a1->a2, 事务B读取了修后的a2, 但是事务A没有提交, 回滚为a1. 所以事务B读取的a2是无效数据
- **不可重复读**: 事务A正准备修改数据a1->a2, 事务B读取了a1, 等事务A提交后, 事务B再次读取了a2.即重复读结果不一样
- **幻读**: 事务 A 准备插入 id 为 3 的数据，所以先查询了 id 为 3 的数据发现没有，准备插入前事务 B 插入了 id 为 3 的数据，那么在事务 A 插入时通过“直接读”发现 id 为 3 的数据已存在，就会插入失败，像出现了幻觉

#### 隔离级别(读写并发)

- **read uncommitted**: 事务B可以读取事务A未提交的数据
- **read committed**: 事务A修改了数据a1->a2, 但是只要没有提交, 事务B不可能读取到a2。仅解决脏读问题
- **repeatable read**: 事务A对某个数据进行update时, 会进行锁. 事务B如果要读取a只能等A提交才行。仅解决不可重复读问题
- **serializable**: 事务只能串行执行。通过 gap 锁解决幻读问题

![img](D:\resource\notePic\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTUxMTE2,size_16,color_FFFFFF,t_70.png)

Q：什么是 MVCC 机制

```
多版本控制机制，数据库的每行数据后有两个隐藏列，分别是创建版本号和删除版本号，其中版本号是系统版本号（自增），也是事务的版本号。
insert 和 delete 分别设置目标行的创建版本号和删除版本号
update 会新增一条记录，同时更新原记录的删除版本号

有了以上机制，事务在读的时候，就能判断版本，在不同隔离级别，对版本有不同的要求。
```

Q：read committed 如何实现（解决了脏读问题）

```
A 事务读取某行时，会查看改行的创建版本号，如果该版本号对应的事务已提交，A 事务就会读取该行数据，否则会通过 undolog 往前查找到该行最新已提交的版本作为读取内容

read committed 级别只是解决了脏读的问题，不可重复读和幻读的问题都存在。
```

Q：repeatable read 如何实现（解决了不可重复读问题）

```
A 事务读取某行时，会查看改行的创建版本号，对创建版本号不仅要求其事务已提交，还要求版本号不大于 A 事务的版本号，实现可重复读。
```

Q：serializable 如何实现（解决了幻读问题）

```
通过锁（行锁、gap 锁、表锁）去实现的
读 id 为 3 的数据，会使用 select * from t where id = 3 for update
就会将 3 左边的索引 key 到右边的索引 key 之间的范围节点上锁，那么 B 事务就不能插入，必须等 A 事务执行完后锁才会释放
```

Q：幻读问题为什么不能通过 MVCC 解决？

[参考](https://juejin.cn/post/6987278773540356126)

```
- 如果是数据插入前读，插入时的直接读一定要读最新的数据，不然可能会出现数据不一致性的问题：A 插入的数据被 B 覆盖掉。
- 如果是读一个范围的 count，多条数据的版本都要与当前事务版本比较，可能性能影响大？
```

综上，MVCC 仅工作在 read committed 和 repeatable read 两个隔离范围，解决了脏读和不可重复读问题。



## 锁

### 共享锁与排他锁

共享锁：允许不占有锁的事务读操作，但不允许写操作。使用 `lock in share mode` 声明

排他锁：不允许不占有锁的事务读写操作。使用 `select for update` 声明

InnoDB 在二级索引上使用共享锁，在主键索引上使用排他锁。



### 行锁、Gap 锁和表锁

行锁：SQL 准确定位到某一行记录，通过对索引加锁，来对行有一定的读写限制。

间隙锁：范围查询时，会对索引项的相应范围加锁，范围中可能有并不存在的记录，这种不存在的记录就叫做间隙。若此时需要插入这些不存在的记录，就会阻塞

表锁：当没有使用索引时，锁会升级成表锁，并发性能大大降低



### MyISAM 与 InnoDB 在锁方面的区别

| 区别/引擎    | MyISAM                               | InnoDB                                                 |
| ------------ | ------------------------------------ | ------------------------------------------------------ |
| 支持锁类别   | 仅支持表锁                           | 行锁/Gap 锁/表锁                                       |
| 死锁问题     | 总是一次获取所需要的全部锁，不会死锁 | 不会一次性获取所有锁，所以可能会出现死锁的相互等待情况 |
| 检查竞争状态 | show status like 'table%'            | show status like 'innodb_row_lock%'                    |



## 索引

索引可以大大提高MySQL的查询速度, 但是也会使数据的INSERT / UPDATE / DELATE变慢, 因为除了处理数据, 还需要处理索引文件, 并且如果在大表上创建了多种组合索引, 索引文件会膨胀很快.

以下情况建立索引对查询速度提升效果不大:

- 小表, 全表扫描效率往往更高
- 索引列大部分内容是重复的

因此, 应该为最常查询和最常排序的数据列建立索引, MySQL里同一个数据表里的索引总数限制为16个

### 不同引擎的索引区别

| 区别点/引擎    | MyISAM                         | InnoDB           |
| -------------- | ------------------------------ | ---------------- |
| 索引值存储     | 使用了前缀压缩技术使得索引更小 | 按原数据格式存储 |
| 引用被索引的行 | 通过数据的物理位置             | 通过主键         |



### 索引分类

索引有不同的分类标准:

- 索引定义时分为: 普通索引(key定义) / 唯一索引(unique key定义, 要求索引列的值都是唯一的) / 主键索引(特殊的唯一索引, 索引列是主键)
- 按照索引中包含字段的个数可以分为: 单列索引 / 组合索引
- 索引还可以分为: 聚簇索引(也称为主键索引, 它的叶子节点存储的数据就是行数据) / 非聚簇索引(称为二级索引, 它的叶子节点存储的数据是主键, 需要再通过主键二次查询)

#### 组合索引

一个唯一的组合索引定义例子如下:

``````sql
unique key name_age_hobby (`name`, `age`, `price`)
``````

组合索引使用时需要满足最左前缀原则, 定义如上的一个组合索引相当于定义了如下三个索引:

`````sql
name
name age
name age price
`````

组合索引在B+树中的存储顺序和层次是从左往右的(可以简单理解为下图, 其实并不是), 正是因为这个原因, 所以要求使用组合索引时满足最左前缀原则

![img](d:/resource/notePic/8c45fe417afbe97127e8c55fe1cd9395_hd.jpg)

#### 聚簇索引和非聚簇索引

InnoDB支持聚簇索引，MyISAM不支持聚簇索引, InnoDB建立聚簇索引的情况如下:

1. InnoDB对主键建立聚簇索引。
2. 如果你不指定主键，InnoDB会用一个具有唯一且非空值的索引来代替。
3. 如果不存在这样的索引，InnoDB会定义一个隐藏的主键，然后对其建立聚簇索引。

**MyISAM的非聚簇索引**

MyISAM引擎将索引和数据分开存储, 索引使用B+Tree数据结构, B+Tree的叶子节点中data存放的是记录的地址, 根据索引得到数据地址, 再根据地址获取数据.

下图是MyISAM索引的原理图：
![img](d:/resource/notePic/758447-20180127161009725-1788644003.png)
这里设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：
![img](d:/resource/notePic/758447-20180127161153647-1802334548.png)



**InnoDB的聚簇索引**

InnoDB引擎的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。
![img](d:/resource/notePic/758447-20180127161454428-323630182.png)
上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整型。

第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。例如，上图为定义在Col3上的一个辅助索引：
![img](d:/resource/notePic/758447-20180127161707334-628982052.png)
这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

使用自增字段作为主键则是一个很好的选择。不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引有以下问题：

- 占用空间变大，一个节点中能存放的索引个数变少，索引能力相对变弱
- 非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一棵B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效

 **InnoDB 与 MyISAM的区别**

MyISAM读性能较高，适合多读的场景，但是大部分场景适合使用InnoDB：它支持事务 / 行锁 / crash-safe 

InnoDB还有一个很好的优势是支持MVCC(多版本控制), MVCC只在READ COMMITED和REPEATABLE READ两个隔离级别下工作, 其比单纯的加锁更高效, MVCC可以使用乐观锁和悲观锁来实现([MySQL-InnoDB-MVCC多版本并发控制](https://segmentfault.com/a/1190000012650596))



### 索引设计原则

- 索引的区分度要尽量高，不然索引的作用会弱很多

- 使用组合索引代替多个列索引

- 索引列值不能为NULL

    索引不会包含有NULL值的列，只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。字段最好都设置为非NULL, 可以使用空值(如0, 空字符串等)代替NULL填充

- 索引字段尽量使用数字型（简单的数据类型）

    好处: 占用空间小, 一个节点上可以放置更多的索引; 走索引时比较简单, 如果是字符串需要逐个字符比较; 使用字符串索引在插入数据时, 索引的B+树需要频繁调整

- 对于列值很长的字符串，使用前缀索引

- 去除冗余 / 不使用的索引: 索引会带来额外消耗, 不必要的索引及时删除



### 索引使用原则

索引使用原则, 主要是考虑如何避免索引失效, 另外是将查询更多/区分度最高的索引放在最左

- 不要在索引列上做运算, 也不要使索引称为函数的参数, 否则索引失效

- 对索引使用like时, like语句不要以通配符开头

    如 `SELECT * FROM mytable WHERE username like 'admin%'`会使用索引, 而`SELECT * FROM mytable WHEREt Name like '%admin'` 则不会使用索引

- or条件: 如果or前的条件中用了索引而后面没用, 那么前面的索引会失效

    应尽量避免在 where 子句中使用 or 来连接条件, 如： 假设num1有索引，num2没有索引，查询语句`select id from t where num1=10 or num2=20`会放弃使用索引，可以改为这样查询： `select id from t where num1=10 union all select id from t where num2=20`，这样虽然num2没有使用索引，但至少num1会使用索引，提高效率

- 尽量不要使用NOT IN、<>、!= 操作, 会导致索引失效
    对于<>，用其它相同功能的操作运算代替，如a<>0 改为 a>0 or a<0

- 组合索引使用时要满足最左前缀原则: (a, b, c)的索引只能使用a / ab / abc三种组合

- 使用索引排序时, ORDER BY也要遵守最左前缀原则, 且有以下限制:

    - 若组合索引的不同列排序顺序(ASC/DESC)不同, 不会走索引排序
    - 如果查询是连接多个表，仅当ORDER BY中的所有列都是第一个表的列时才会使用索引
    - 如果WHERE或者JOIN子句中对前导列指定了常量, ORDER BY后可以不满足最左前缀原则, 而是WHERE + ORDER BY 一起满足最左前缀原则

    对于所有索引排序失效的情况, 会使用filesort文件排序(MySQL在内存中使用自己的排序算法排序)

    ![img](d:/resource/notePic/v2-19d7202ee71287a606f644837d0c19cc_hd.jpg)

- 如果列类型是字符串，那么在 where 条件中需要把字符常量值用引号引起来，否则即便列上有索引，MySQL 也不会用, 因为MySQL 默认把输入的常量值进行转换以后才进行检索

    如 `select id , age from people where name = jack`不会走name的索引, `select id , age from people where name = "jack"`会走name索引
    
    **隐式转换**：若某索引字段`bpn`类型是`varchar(20)`，当使用条件`where bpn = 1400000012`时，因为右侧是数字，MySQL策略是将bpn转换为数字之后再比较，函数作用于索引字段，索引失效；因此需要使用`where bpn = '1400000012'`，有时候右边并不是由程序员写死，而是框架自动填充，需要避开这个坑
    
- 强制走某个索引：当判断条件中有2个索引(包含主键索引)时，数据库一般会选择走主键索引，但是有时候其实走非主键索引会更快，此时需要采取一定的技巧

    - 技巧1：指定强制索引：select * from product forcr index(createTime) where ...
    - 技巧2：在不想走索引的列上 + 0，使其失效




### 索引性能查看

只有当数据库里已经有了足够多的测试数据时，它的性能测试结果才有实际参考价值。如果在测试数据库里只有几百条数据记录，它们往往在执行完第一条查询命令之后就被全部加载到内存里，这将使后续的查询命令都执行得非常快——不管有没有使用索引。只有当数据库里的记录超过了1000条、数据总量也超过了 MySQL服务器上的内存总量时，数据库的性能测试结果才有意义。

- 使用 explain + 查询语句 查看查询语句的执行情况字段, 主要看type key 和 rows三个列, 查询的列rows显然越小越好,  key表示查询使用的索引命名称, type如果是all代表全表扫描, type为index代表虽然用了索引, 但是是遍历索引列([参考](https://www.zhihu.com/question/36996520)). 只有当type是ref时, 才是正确使用索引的姿势, 其会根据特定的算法快速查找某个符合条件的索引.

    未走索引:

    ![1565059178309](d:/resource/notePic/1565059178309.png)

    走索引:

    ![1565059205832](d:/resource/notePic/1565059205832.png)

- 使用`show status like "Handler_read%"` 查看索引使用情况

    ![1565059332879](d:/resource/notePic/1565059332879.png)

    Handler_read_key 代表索引被读取的次数, 如果索引正常工作, 这个数值会很高.

    Handler_read_rnd_next 代表数据文件读下一行的请求数, 这个数值越高(相对), 说明读取下一行的请求次数越多, 表明查询效率越低(相对)



### 索引底层结构

#### Hash索引和B+树索引

**Hash索引:** 因为Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。**所以，哈希索引只适用于等值查询的场景。**

**B+Tree结构:** B+ 树是一种**多路平衡查询树**，它节点是天然有序的（左子节点小于父节点、父节点小于右子节点），对于范围查询的时候不需要做全表扫描

- B+Tree相比红黑树, 它的节点是多向的. 因此搜索时间复杂度更小
- 将B+Tree的节点大小设置为磁盘读取的一个页大小, 磁盘每次读取刚好读取一个节点,减少IO次数

节点包含索引 key 和指针，指针指向的是下一层节点，并且被指向的节点中索引 key 值的上下限是确定的，最终结果就是找到确定的索引 key 或者未找到。

**B+ Tree索引和Hash索引区别？**

- 哈希索引适合等值查询，但是无法进行 **范围查询 / 模糊查询 / 利用索引排序** 

- 哈希索引一定需要回表查询

- 如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题

#### B树

B树是一种平衡多叉查找树，下图是5阶B树 。B树在插入删除新的数据记录会破坏B-Tree的性质，因为在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。
![1563265624827](d:/resource/notePic/1563265624827.png)
**m阶B树的特点**

- 每个节点至多可以拥有m个子节点
- 每个节点中的关键字都是非降序排列的, 同一层不同节点的关键字也是非降序排列的
- 根节点到所有叶子节点的路径长度都相同
- 任何一个关键字只出现在一个节点中, 并且该节点会存储关键字对应的信息, 因此搜索可能在非叶节点结束, 其性能整体相当于一个搜索二叉树

**B树节点存放的信息**

节点存放的信息主要有: 当前节点关键字个数n, 关键字数组keyword, 信息数组info, 指针数组children.

查询时, 如果能够击中keyword中某个元素, 就可以直接在info中提取信息返回结果. 如果不能, 则根据查询词大小在keyword中的位置, 从children中提取下一个寻找的节点.



#### B+树

![1565699535075](d:/resource/notePic/1565699535075.png)

作为B树的加强版，B+树与B树的**差异**在于

- 非叶子节点只存放关键字, 不存放关键字对应的信息

- 一个关键字一旦出现, 就会从出现的一层开始, 在下面的每层都会继续出现, 直到叶子节点

- 叶子节点除了存放关键字, 还会存放关键字对应的信息. 所以查找时, 即使击中了关键字, 也必须一直走到叶子节点, 才能取到信息. 因此B+树的所有关键字查找深度都是一样的

- 一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。即关键字大小相邻的叶子节点会存在访问指针, 当搜索连续数据时, 可以加快访问速度

  ![img](d:/resource/notePic/758447-20180126171338850-1455023219.png)
  

#### 组合索引的B+树

组合索引的B+树与单列索引的B+树是一样的，只是每个节点中的key索引数据不再是一个字段而是多个字段，并且它对应的指针在指向下一层的时候要符合最左前缀原则。

所以组合索引的 B+ 树，上层节点中的 key 只有最左索引有区分，如果不满足最左前缀使用原则，就无法使用该索引。

#### 为什么使用B+树做索引而不用B树?

因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少, 指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低

(B+树每次搜索都会走完一个树的高度, 一个节点就是一个页, 一页认为是一次IO(实际可能一次IO会加载多个邻近的页) 所以树越高, IO次数变大可能性越高)

#### 为什么使用B+树做索引而不用红黑树?

**非线性的搜索时间复杂度:** 因为B+树是平衡多叉树, 搜索时间复杂度是非线性的, 且B+树出度大, 搜索时间复杂度相比普通平衡二叉树更小

**IO次数少:** 因为索引往往以索引文件的形式存储在磁盘中, 磁盘的读取速度相对主存慢很多, 减少IO次数, 可以有效提高搜索速度.

根据局部性原理：当一个数据被用到时, 其附近的数据也马上会被用到. 所以计算机经常会预读数据, 预读时以页为单位(页是计算机管理存储器的逻辑块, 大小通常为4KB), B+树节点在创建时申请大小刚好为一页, 充分利用了预读空间. 而红黑树显然做不到这点

### 常见面试问题

Q：有组合索引 a，b，c，现使用 SQL：`select * from test where a = 'a' and b > 'b' order by c `，会使用几个索引？

```
2 个（a 索引和 b 索引）。在 b 相等的所有节点里，c 是有序的，一旦 b 是范围，那么在多个范围值下，c 就变得整体无序了
```

Q：有组合索引 a，b，c，现使用 SQL：`select * from test where a = 'a' and b like 'b%' and c = 'c' `，会使用几个索引？

```
两个，存储引擎规定，如果索引列中有范围查询，那么其后面的索引列就无法使用。因为如果范围很大时，用索引还不如直接将范围值取出来在内存中遍历比对
```

Q：为什么组合索引要满足最左前缀使用原则？

```
因为组合索引在 B+ 树中是按顺序存储的，B+ 树从上往下搜索时，是先按最左列进行排序区分的，当最左列确定为某值后，才按后面的列再次进行排序区分
```

Q：distinct、group By 和 order By 是怎么实现的？

```
distinct 依赖于 group By，group By 依赖于 order By
order By 的列如果是索引列，由于 B+ 树是查找树，天然支持排序，那么 order by 的性能就会很好。
如果不是索引列，那么需要将 id 和排序列取出来在内存中排序，排序完后再用 id 去取记录行
```

Q：什么时候使用前缀索引，它有什么优点和缺点？

```
当某个列值是一个很长的字符串时，如果做全值索引成本就会很大，所以字符串索引一般会限制前缀的长度，使索引建立后的写和读性能达到一个平衡，至于索引的前缀长度，可以通过 sql 去查看不同前缀长度的 distinct，去看它们的区分度来确定。

缺点是：前缀索引无法 order by，因为前缀索引只比较了一部分，假设一个节点中前缀索引 key 就一个，但是对应的 value 值有很多，此时它们并不一定是有序的。
```





## 查询优化

### 慢SQL原因分析

[为什么我的SQL语句执行很慢](http://note.youdao.com/noteshare?id=5efc27381798d9890291d3d83c0ae26f&sub=ABA3AB2C8205484096A12159FC3D412F)

如果是偶尔执行很慢, 可能有以下两个原因:

- 数据库正在刷新脏页. 数据库在插入数据时, 首先在内存中的redo log记录插入命令, 空闲时会执行日志中的命令将记录持久化到硬盘中, 当数据插入很频繁时, redo log很快就会满, 此时数据库为了防止数据丢失, 就会优先执行日志命令, 持久化数据到硬盘, 因此SQL语句执行较慢.
- 遇到了表锁或行锁. 即SQL语句执行的表或行, 被其他用户正在操作处于锁的状态

如果是经常执行的很慢, 那就是SQL语句本身的原因:

- 没用上索引, 可能是因为SQL语句使用的字段没有建立索引, 也有可能是因为对索引进行了运算或函数操作, 导致没有使用索引
- 数据库选错了索引. 比如执行`select * from product where price > 100 and price < 1000`这条SQL语句, 即使price是索引, 数据库也不一定使用. 因为假设price不是主索引(对应字段为主索引, 主索引对应数据是行记录), 数据库会预测根据price索引查询的记录数和直接全表扫描的记录数, 哪一个更优. 如果走price索引, 那么一次查询需要查两次(先查主索引, 再查行数据), 万一整个表都满足条件, 那么相当于全表扫描两次, 显然是不划算的. 所以数据库会根据price的"基数"预测, price在数据库中相同值越少, 它的基数越高, 区分度越高, 走price索引查询越快. 基数预测是通过采样的形式. 因此可能price 基数很高, 但是采样值计算出来的基数很小, 数据库就会弃用price索引, 而直接全表扫描. 当然这只是其中一种可能



### 避免索引失效

参考[索引使用原则](#索引使用原则)

### sql规范

- 不要使用 selcet *, 搜索列一定要指明

- 当只需要查询一条数据时, 可以使用`limit 1`, 此时explain中type为constant, 限制更高

- 分页查询limit后的offset不宜过大，因为数据库是提取offest+N行，放弃offset行，当offset非常大时就很耗时，所以可以使用子查询优化这种分页查询

    ![1566375009660](d:/resource/notePic/1566375009660.png)
    
    或者也可以根据当前页的某些信息(前端返回给后端)，确定下一页。此时limit后只用接一个参数即可
    
    ```sql
    SELECT   * 
    FROM     operation 
    WHERE    type = 'SQLStats' 
    AND      name = 'SlowLog' 
    AND      create_time > '2017-03-16 14:00:00' 
    ORDER BY create_time limit 10;
    ```
    
- 少用`in`和`not in`：因为它们使用嵌套查询，即可能一条sql语句要查表很多次。尽量将sql语句改造成关联查询(left join)，笛卡尔积更快；或使用`union`合并多个结果





## 分库分表

#### 什么情况适合分表

当某张表的数据量已经达到千万甚至上亿，同时日增数据量在 2% 以上。当然这些数字并不是绝对的，最重要的还是对这张表的写入和查询都已经影响到正常业务执行，比如查询速度明显下降，数据库整体 IO 居高不下等。

分表分为：水平分表和垂直分表，水平分表目的是为了减少单表的记录数量，垂直分表可以将部分少用字段或者占用内存多的字段从原表中分出来。垂直分表一般要配合业务，表结构设计时就要考虑，而很少在上线后再做垂直分表改造。

#### 分表策略

最常用的分表策略是Hash, 选择表中一个数字字段, 一般是某个自增的Id, 假设插入某条数据是n = Id%N, 那么这条数据就会被插入到第n个表中(N是分表的总表数量). 

分表数量N一般也选择2^n, 尽量不要选太小. 毕竟如果后续小表也达到瓶颈需要再进行一次分表扩容，那是非常痛苦的。

![1565592909959](d:/resource/notePic/1565592909959.png)

除了Hash, 对于归档类表(比如月账单之类), 可以使用日期归档分表, 比如每个月对应一张表. 这种策略风险是如果某个月的数据量激增, 可能会带来问题. 当然, 还可以先Hash再归档, 双重分表, 这样可以带来更大的扩容.

![1565593119351](d:/resource/notePic/1565593119351.png)

#### 数据迁移

分表规则弄好后其实只是完成了分表的第一步，真正麻烦的是数据迁移，或者说是如何做到对业务影响最小的数据迁移. 为了不影响业务, 会做兼容处理

分表改造上线后，所有新产生的数据写入分表，但对历史数据的操作还走老表，这样就少了数据迁移这一步骤。当新数据产生的足够多时（我们是两个月时间），几乎所有的操作都是针对于分表，再从库启动数据迁移(迁移过程老表是无法提供服务的, 因为此时大部分服务走新表, 并且迁移过程一般放在凌晨两三点)，数据迁移完毕后所有的数据操作都走新表, 不再路由判断

#### 分表带来的问题

问题1：分表要考虑不同表中id的唯一性，也就是考虑分布式主键，有以下常用方案：

- 多数据库自增主键 + 分段提取：每个数据库自增主键的起始位置和自增步长可以调整，保证各数据库之间的自增主键不会重复，另外从数据库中提取主键时，一次可以提取一个范围，避免频繁连接数据库。虽然这样存在空主键的风险：若批量提取主键后宕机了，这段主键就空了
- redis自增：支持高并发高性能，但是存在持久化风险
- snowflakes算法：64bit = 1bit固定0 + 41bit时间戳 + 10bit机器码 + 12bit序列号(每ms4096个ID)，美团的Leaf算法中，机器码workerID是通过zookeeper的顺序节点序号生成的

问题2：分表后查询需要 分页 和 排序时，可能要多次查询，再处理合并结果

问题3：事务变得复杂，变成了分布式事务

#### 什么情况适合分库

每个数据库支持的连接数是有限的，若业务中对单库的连接数超过了一定限制，就需要分库。分库后，通过负载均衡代理控制每次sql需要连接的数据库

分库方式：根据业务进行分库；根据数据冷热(访问频次)进行分库



## MySQL问题

### 一条sql语句的执行过程

![1565580438666](d:/resource/notePic/1565580438666.png)

1. 通过连接器，客户端与MySQL建立连接
2. update语句会把**T表上的所有查询缓存清空**
3. 分析器会通过词法分析和语法分析识别这是一条更新语句
4. 优化器会决定使用id这个索引（聚簇索引）
5. 执行器负责具体执行，找到匹配的一行，然后更新
6. 更新过程中还会涉及**redolog**（重做日志）和**binlog**（归档日志）的操作

简单来说 MySQL 主要分为 Server 层和存储引擎层：

- **Server 层**：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。
- **存储引擎**： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。**

查询sql语句的大致执行过程: 首先经过连接器进行权限校验, 然后经过分析器, 进行词法和语法分析, 然后经过优化器, 决定sql语句的执行方式, 最后通过执行其进行查询.

对于更新sql语句(增删改), 其在执行时还有日志模块, 进行更新的同时, 会将sql语句记录在日志中, 以便于事务回滚或者灾后恢复.

### 大表的常见优化手段

1. 限定数据范围: 禁止不带任何限制的数据查询语句,如 select * from user
2. 读写分离: 数据库分离方案,主库负责写,从库负责读
   主库负责写操作,以及对实时性要求较高的读操作.从库负责大部分读操作
   主从负责各自的读和写,缓解了锁的竞争
   从库可以使用MyISAM引擎,提高读效率
3. 垂直拆分和水平拆分: 将一张表按列或按行拆分,成为多张表,可以提高读写效率.但是拆分后,事务维护就很复杂



### MySQL的读写分离和主从延时问题?

Q:如何实现 MySQL 的读写分离？MySQL 主从复制原理的是啥？如何解决 MySQL 主从同步的延时问题？

````
读写分离:使用主从架构,一主多从,主库负责写操作,从库负责读操作,利用主从复制保持数据一致.
主从复制原理:主库每条写操作的sql命令都会保存到日志中,主从之间会有一个IO线程,复制这个日志(复制成功后会给主库一个ack),从库中会有一个sql线程从复制的日志中读取sql并执行,从而保持数据一致性.
````

```
MySQL的主从同步延时问题:当主库的写操作并发量很高时,主从延时可能会有几百ms,此时可以采用分库+并行复制.即将主库拆分成多个主库,每个主库的并发就减少了,然后从库采用多个线程,从多个主库中复制sql日志并执行,可以尽量减少同步延时.
注意,因为同步延时的存在,读写分离的数据库,在写代码的时候最好不要有这种逻辑:插完数据后,立即查询.刚插完很可能查询不到.
```



### join的底层实现原理

join大概有三种可能, 第一种类似于两重for循环, 会将左表中每行都拿去与右表全表扫描; 第二种是当关联条件有索引时, 会先查询满足条件的索引, 再通过索引回表查询; 第三种是利用缓冲区, 首先分别查询左表和右表满足关联条件的记录, 放入缓冲区, 再做关联.



### 数据库连接池数量设置多少合适

[参考](https://www.cnblogs.com/javastack/archive/2020/03/26/12575435.html)

> **连接数 = ((核心数 \* 2) + 有效磁盘数)**

`核心数 * 2` 是因为一般情况下，实测性能最佳，有效磁盘数是因为数据库在取数时，需要调整磁盘头访问位置，这个等待的时间线程可以去干点其他事。

最好的情况是，尽量小和适合的连接池数量 + 适度长的等待队列





### 数据库的三范式

1NF：要求列的原子性，列值是不可再分的。比如地址信息整体作为一列是不合适的，可将其拆分为省、市、详细地址多列

2NF：要求属性完全依赖于主键。即每一列可以通过一个主键属性来唯一标识，这样一定程度上避免数据的冗余，比如学生信息表里，学院的名称、代码、简介等信息是不完全依赖于学生信息的主键，所以应该抽出来成为一张学院信息表，它们完全依赖于学院信息的主键。

3NF：要求非主属性不能依赖其它非主属性，比如学生信息表里，每个学生信息既有学院的 id，又有学院的名称等信息，那么学院的名称等信息就会依赖学院的 id 这个非主属性（在学生信息表里它是非主属性），应该把学院名称这些属性去掉，消除传递依赖。

总结：三大范式只是一般设计数据库的基本理念，可以建立冗余较小、结构合理的数据库。如果有特殊情况，当然要特殊对待，数据库设计最重要的是看需求跟性能，需求>性能>表结构。所以不能一味的去追求范式建立数据库。
